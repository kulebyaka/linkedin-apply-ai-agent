# Implementation Plan & Status

## Functional requirements:

Every hour, based on a set of filters (in the future, filters will be built based on the user's verbal request), it makes a request and the Linkedin API returns a set of positions. LLM evaluates each position to determine whether it actually matches the request (the description may contain information that it is not actually a remote position, etc.). Positions that pass the filter are matched with the user's data set (very comprehensive CV in JSON format). Based on the position description and CV a new JSON that represents the CV with recomposed relevant information to the position information is generated by llm. A PDF is created from the JSON. The agent goes to LinkedIn (not sure how, via browser mcp or using some skill) and attempts to apply for the position. If unsuccessful, it sends a notification to the user (webhook) On every step it should be able to leverage the HITL if there is some uncertainty about successfulness of the current step. Also we need HITL on the very last step to review the modified CV and the position before submitting. Do it it batches or in some tinder-like UI so user sees the job position + new CV and could approve (swipe right) or decline (swipe left and write a little note, why it is declined after swiping) or ask for try again (swipe down, also add the note what to do differently)

## Non-Functional requirements:

- Self-hosted on a VPS
- Supports at least 3 different LLM providers (e.g., OpenAI, DeepSeek, Grok, etc.) and can switch between them easily
- Modular design to allow easy updates and maintenance
- Prefer Playwright for browser automation

## Implementation Status

| Component | Status | Notes |
|-----------|--------|-------|
| **Two-Workflow Architecture** | âœ… Complete | Preparation + Application workflows with HITL boundary. |
| **LLM Provider Layer** | âœ… Complete | Implemented in `src/llm/provider.py`. |
| **Job Source Adapters** | ğŸŸ¡ Interface | `src/services/job_source.py` - interface only, no implementation. |
| **Data Access Layer (DAL)** | ğŸŸ¡ Stubs | `src/services/job_repository.py` - stubs only, no persistence. |
| **Preparation Workflow** | âœ… Complete | `src/agents/preparation_workflow.py` - extract â†’ filter â†’ compose â†’ PDF â†’ save. |
| **Retry Workflow** | âœ… Complete | `src/agents/retry_workflow.py` - regenerate CV with user feedback. |
| **Application Workflow** | ğŸŸ¡ Stubs | `src/agents/application_workflow.py` - stubs only, deep agent not implemented. |
| **Compose Tailored CV** | âœ… Complete | `src/services/cv_composer.py` fully implemented. |
| **Generate PDF** | âœ… Complete | `src/services/pdf_generator.py` fully implemented. Uses WeasyPrint + Jinja2. |
| **HITL API Endpoints** | âœ… Complete | `src/api/main.py` - batch review, approve/decline/retry endpoints. |
| **Unified Data Models** | âœ… Complete | `src/models/unified.py` - Pydantic models for new architecture. |
| **Job Filter (LLM)** | ğŸ”´ Pending | `src/services/job_filter.py` skeleton exists. |
| **Browser Automation** | ğŸ”´ Pending | `src/services/browser_automation.py` is a skeleton. |

## Two-Workflow Pipeline Architecture

The system uses a **two-workflow pipeline** split at the HITL boundary, enabling batch review of generated CVs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PREPARATION WORKFLOW                                 â”‚
â”‚  (runs continuously, processes jobs, saves to DB for batch review)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Job Source â”€â”€â–º Extract â”€â”€â–º Filter â”€â”€â–º Compose CV â”€â”€â–º Generate PDF â”€â”€â–º DB â”‚
â”‚   (URL/Manual)                                                    (pending) â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    HITL BOUNDARY      â”‚
                        â”‚  (Tinder-like batch   â”‚
                        â”‚   review UI)          â”‚
                        â”‚                       â”‚
                        â”‚  âœ“ Approve            â”‚
                        â”‚  âœ— Decline            â”‚
                        â”‚  â†» Retry + feedback   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ APPLICATION WORKFLOWâ”‚  â”‚  RETRY WORKFLOW â”‚  â”‚      DECLINED       â”‚
â”‚ (triggered on       â”‚  â”‚  (regenerate CV â”‚  â”‚   (no action)       â”‚
â”‚  approve)           â”‚  â”‚   with feedback)â”‚  â”‚                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Load â”€â”€â–º Apply â”€â”€â–º  â”‚  â”‚ Load â”€â”€â–º Composeâ”‚
â”‚          Update DB  â”‚  â”‚   â”€â”€â–º PDF â”€â”€â–º   â”‚
â”‚                     â”‚  â”‚      Update DB  â”‚
â”‚ (stubs only -       â”‚  â”‚                 â”‚
â”‚  deep agent future) â”‚  â”‚ (loops back to  â”‚
â”‚                     â”‚  â”‚  HITL pending)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow Files

| Workflow | File | Description |
|----------|------|-------------|
| Preparation | `src/agents/preparation_workflow.py` | Main pipeline: job input â†’ CV PDF â†’ DB |
| Retry | `src/agents/retry_workflow.py` | Re-compose CV with user feedback |
| Application | `src/agents/application_workflow.py` | Apply to job (stubs only) |

### Workflow Modes

- **MVP Mode** (`mode="mvp"`): Generate PDF only, skip HITL, status = `completed`
- **Full Mode** (`mode="full"`): Generate PDF, save to DB with status = `pending` for HITL review

### Job Sources

Defined in `src/services/job_source.py` (interface only):

| Source | Description | Status |
|--------|-------------|--------|
| `url` | Extract job from external URL (lever.co, greenhouse.io, etc.) | Interface only |
| `manual` | User provides job description directly | Interface only |
| `linkedin` | LinkedIn API/scraping (future) | Not implemented |

## API Endpoints

### Unified Endpoints (New)

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/jobs/submit` | Submit job for CV generation (URL or manual input) |
| GET | `/api/jobs/{job_id}/status` | Get job status and details |
| GET | `/api/jobs/{job_id}/pdf` | Download generated CV PDF |
| GET | `/api/hitl/pending` | Get all jobs pending HITL review |
| POST | `/api/hitl/{job_id}/decide` | Submit HITL decision (approve/decline/retry) |
| GET | `/api/hitl/history` | Get application history |

### Legacy Endpoints (Backward Compatible)

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/cv/generate` | Submit CV generation (uses preparation_workflow with MVP mode) |
| GET | `/api/cv/status/{job_id}` | Get CV generation status |
| GET | `/api/cv/download/{job_id}` | Download generated CV PDF |

## Data Models

Defined in `src/models/unified.py`:

- `JobSubmitRequest` - Input for job submission (source, mode, url/job_description)
- `JobSubmitResponse` - Response with job_id and status
- `HITLDecision` - User decision (approved/declined/retry + feedback)
- `HITLDecisionResponse` - Response after decision processed
- `PendingApproval` - Job details for HITL review UI
- `JobStatusResponse` - Full job status with CV and PDF info
- `JobRecord` - Database record for job persistence
- `ApplicationHistoryItem` - History entry for completed jobs

## Deleted Files

The following files were removed as part of the two-workflow architecture refactoring:

| File | Reason |
|------|--------|
| `src/agents/mvp_workflow.py` | Superseded by `preparation_workflow.py` with `mode="mvp"` |
| `src/agents/workflow.py` | Superseded by new two-workflow architecture |
| `src/services/cv_generation_service.py` | Functionality moved to workflows |

## Architecture: Job Application Automation Agent

Orchestrated Workflow with LangGraph (Modular Pipeline)

Overview: This option keeps a Python-centric solution but introduces a structured workflow/orchestration framework â€“ specifically LangGraph (a 2025 successor to LangChain that uses explicit graph/state machine definitions for LLM-driven tasks). Instead of one big script, we define the pipeline as a directed graph of tasks: nodes for each step (job search, filtering, CV crafting, application, etc.) and edges to control flow (including conditional branches and human approval loops). All components can still run on one VPS (perhaps as separate threads or async tasks), but logically they are modular. This design provides more control and observability than a basic script, and it naturally integrates the HITL steps and multi-model support through the LangGraph framework features.

### Design Principles

1. **Two-Workflow Split**: Separating at HITL boundary allows batch processing of pending approvals
2. **Mode Parameter**: Single workflow handles both MVP (immediate) and Full (HITL) modes
3. **Job Source Adapters**: Abstract interface for URL extraction, manual input, LinkedIn API
4. **Repository Pattern**: DAL abstraction for future database persistence (currently in-memory stubs)

### Node Descriptions

**Preparation Workflow Nodes:**

1. **extract_job_node** - Extracts structured job data from raw input (URL or manual)
2. **filter_job_node** - LLM evaluates job suitability (currently passthrough)
3. **compose_cv_node** - LLM tailors CV to job description
4. **generate_pdf_node** - Creates PDF from tailored CV JSON
5. **save_to_db_node** - Persists job record (MVP: completed, Full: pending)

**Retry Workflow Nodes:**

1. **load_from_db_node** - Loads job record for retry
2. **compose_cv_node** - Re-composes CV with user feedback
3. **generate_pdf_node** - Regenerates PDF
4. **update_db_node** - Updates record, returns to pending status

**Application Workflow Nodes (Stubs):**

1. **load_from_db_node** - Loads approved job
2. **apply_deep_agent_node** - Browser automation via Playwright MCP (not implemented)
3. **apply_linkedin_node** - LinkedIn Easy Apply automation (not implemented)
4. **apply_manual_node** - Marks job for manual application
5. **update_db_node** - Records application result

### Multi-LLM Support

LangGraph is model-agnostic; we can configure different LLM nodes to use different providers. For example, perhaps use a cheaper model (like DeepSeek or Grok) for the filtering step and a more powerful one (GPT-4) for generating the tailored CV content. Each LLM node can be configured with an API key and model name, and switching providers is as easy as changing that configuration.

### HITL Integration

The two-workflow architecture enables true batch HITL:

1. **Preparation Workflow** runs continuously, generating CVs and saving them with `status=pending`
2. **HITL UI** (Tinder-like) queries `/api/hitl/pending` to show batch of pending jobs
3. **User reviews** each job+CV, swipes right (approve), left (decline), or down (retry with feedback)
4. **Decisions** submitted via `/api/hitl/{job_id}/decide` trigger appropriate workflow:
   - Approve â†’ Application Workflow (stubs)
   - Decline â†’ Mark as declined, no action
   - Retry â†’ Retry Workflow with feedback

## Next Steps

1. **Implement Job Source Adapters** - URL extraction using HTTP + LLM, manual input processing
2. **Implement DAL** - SQLite or PostgreSQL persistence for job records
3. **Build HITL Frontend** - Tinder-like React/Vue UI for batch review
4. **Implement Application Workflow** - Deep agent with Playwright MCP for browser automation
5. **Add Job Filter Logic** - LLM-based job suitability evaluation
6. **LinkedIn Integration** - Job fetching and Easy Apply automation
